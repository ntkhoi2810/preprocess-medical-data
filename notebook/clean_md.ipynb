{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def chunk_markdown_by_h3(markdown_content: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split a markdown string into chunks based on level 3 headings (### headings).\n",
    "    Each chunk starts with a level 3 heading and includes all content until the next level 3 heading.\n",
    "    \n",
    "    Args:\n",
    "        markdown_content: The markdown content to split\n",
    "        \n",
    "    Returns:\n",
    "        A list of markdown chunks\n",
    "    \"\"\"\n",
    "    # Pattern to match level 3 headings\n",
    "    h3_pattern = r'^###\\s+.*$'\n",
    "    \n",
    "    # Split the content by level 3 headings\n",
    "    lines = markdown_content.split('\\n')\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    \n",
    "    for line in lines:\n",
    "        # If we find a level 3 heading and we have content in current_chunk,\n",
    "        # save the current chunk and start a new one\n",
    "        if re.match(h3_pattern, line) and current_chunk:\n",
    "            chunks.append('\\n'.join(current_chunk))\n",
    "            current_chunk = [line]\n",
    "        # If we find a level 3 heading and have no current chunk, start a new chunk\n",
    "        elif re.match(h3_pattern, line):\n",
    "            current_chunk = [line]\n",
    "        # Otherwise add the line to the current chunk if we have one\n",
    "        elif current_chunk:\n",
    "            current_chunk.append(line)\n",
    "    \n",
    "    # Add the last chunk if it exists\n",
    "    if current_chunk:\n",
    "        chunks.append('\\n'.join(current_chunk))\n",
    "    \n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_markdown_file_by_h3(file_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Read a markdown file and split it into chunks based on level 3 headings.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the markdown file\n",
    "        \n",
    "    Returns:\n",
    "        A list of markdown chunks\n",
    "    \"\"\"\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    return chunk_markdown_by_h3(content)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = chunk_markdown_file_by_h3('/teamspace/studios/this_studio/preprocess-medical-data/benhhoc_4.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cloudspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
